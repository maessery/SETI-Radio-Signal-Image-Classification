{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport keras\nimport tensorflow as tf\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras import Sequential\nfrom keras.layers import Dense,Activation, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\nfrom keras.models import Model\nfrom keras.metrics import categorical_crossentropy\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,max_error, explained_variance_score,median_absolute_error, accuracy_score,classification_report,confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV,  cross_validate,  cross_val_score \nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import *\nimport cv2\nimport math\nimport joblib\nfrom scipy import stats\nimport gc\n\n\nimg_w= 256\nimg_h=256","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:48:09.615462Z","iopub.execute_input":"2022-01-25T16:48:09.615783Z","iopub.status.idle":"2022-01-25T16:48:15.830111Z","shell.execute_reply.started":"2022-01-25T16:48:09.615692Z","shell.execute_reply":"2022-01-25T16:48:15.829360Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_path= \"../input/seti-data/primary_small/train/\"\nvalid_path= '../input/seti-data/primary_small/valid/'\ntest_path= '../input/seti-data/primary_small/test/'","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:48:15.831698Z","iopub.execute_input":"2022-01-25T16:48:15.831956Z","iopub.status.idle":"2022-01-25T16:48:15.838234Z","shell.execute_reply.started":"2022-01-25T16:48:15.831922Z","shell.execute_reply":"2022-01-25T16:48:15.837463Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class ImageData:\n\n    def __init__(self, filepath):\n        self.filepath= filepath\n        self.X_data= []\n        self.y_data= []\n        self.X_gray= []\n        self.X_binary=[]\n        self.classes=[]\n        self.y_categorical= []\n           \n            \n            \n    def split_and_resize(self): \n\n        self.classes= sorted(os.listdir(self.filepath))\n\n        for c in range(len(self.classes)):\n            path = os.path.join(self.filepath, self.classes[c])\n            signal_type= self.classes[c]\n            \n            for i in os.listdir(path):\n                img= cv2.imread(os.path.join(path, i))\n                img= cv2.resize(img, (256, 256))\n                \n                self.X_data.append(img)\n                self.y_data.append(signal_type)\n                \n        return np.array(self.X_data), np.array(self.y_data)\n\n    \n    def grayscale(self):\n\n        for i in range(len(self.X_data)):\n            x= cv2.cvtColor(self.X_data[i], cv2.COLOR_BGR2GRAY)\n            self.X_gray.append(x)\n\n            \n    \n    def create_binary_image(self):\n        self.grayscale()\n        for i in range(len(self.X_gray)):\n            img= np.where(self.X_gray[i]>100,1,0)\n            self.X_binary.append(img)\n        return np.array(self.X_binary)\n            \n    \n    def create_categorical_label(self):\n        self.y_categorical = to_categorical([self.classes.index(i) for i in self.y_data])\n        return self.y_categorical\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:48:15.839722Z","iopub.execute_input":"2022-01-25T16:48:15.839984Z","iopub.status.idle":"2022-01-25T16:48:15.857101Z","shell.execute_reply.started":"2022-01-25T16:48:15.839951Z","shell.execute_reply":"2022-01-25T16:48:15.856167Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class FeatureEngineering:\n    \n    def __init__(self):\n        self.lr_rmse=[]\n        self.lr_max_error= []\n        self.lr_spread= []\n        self.lr_av_slope= []\n        self.lr_slope= []\n        self.y_int= []\n        \n        self.num_gaps= []\n        self.mean_squiggly =[]\n        self.num_bright_pix =[]\n        self.pct_bright_lines =[]\n        self.noisy= []\n        self.biggest_gap=[]\n#         self.frequent_gap=[]\n\n        \n    \n        self.Features_DF = pd.DataFrame()\n        \n    \n    def make_df(self):\n\n        img_tuple = [([(i,x,y) for x, y in enumerate(j)]) for i, j in enumerate(self.temp)]\n\n        \n        new_list=[]\n        for x in range(256):\n            for y in range(256):\n                new_list.append(img_tuple[x][y])\n                \n                   #create df from the list, filter for only bright pixels (ie, 1 values)\n        df= pd.DataFrame(new_list).rename(columns={0:'Y', 1:\"X\", 2:'Bright'})\n        df= df[df['Bright']==1]\n        df.drop(columns='Bright', inplace=True)\n        df.reset_index(inplace=True, drop=True)\n        self.brightpix_df= df\n        self.num_bright_pix.append(len(self.brightpix_df))\n        return self.brightpix_df\n    \n\n        \n    def lin_reg(self, binary_array):\n\n        \n        binary_df =  pd.DataFrame(self.make_df())\n        Y= binary_df['Y']\n        X= binary_df.drop(columns='Y')\n        \n        LinReg = LinearRegression()\n        LinReg.fit(X,Y)\n        \n        self.y_pred= LinReg.predict(X)\n        \n        self.lr_rmse.append(math.sqrt(mean_squared_error(Y, self.y_pred)))\n        self.lr_max_error.append(max_error(Y, self.y_pred))\n        self.lr_av_slope.append(abs(LinReg.coef_))\n        self.lr_slope.append(LinReg.coef_)\n        self.y_int.append(LinReg.intercept_)\n        self.lr_spread.append(np.max(X)- np.min(X))\n        \n    def gap_detector(self):\n        self.num_gaps.append(len(self.brightpix_df[self.brightpix_df.Y.diff()> self.thresh]))\n            \n    def mean_squiggliness(self):\n        if self.brightpix_df.X.diff().apply(abs).mean() ==np.nan:\n            self.mean_squiggly.append(0)\n        else:\n            self.mean_squiggly.append(self.brightpix_df.X.diff().apply(abs).mean())\n            \n\n    def big_and_most_gap(self):\n        \n        diffs = self.brightpix_df.Y.diff()\n        gap_info= pd.DataFrame(diffs.value_counts()).reset_index().rename(columns={'index':'Gap Size', 'Y':'Gap Freq'})\n        freq_gap = gap_info.sort_values(by='Gap Freq', ascending=False)\n        \n        \n                                        # ***********\n        if np.max(gap_info['Gap Size']) > self.thresh:\n            self.biggest_gap.append(np.max(gap_info['Gap Size']))\n        else:\n            self.biggest_gap.append(0)\n            \n\n    \n    def find_bright_lines(self):\n        lines=[]\n        \n        for line in range(256):\n            if np.max(self.temp[line]) >0:\n                lines.append(1)\n        self.pct_bright_lines.append(len(lines)/256)\n        \n\n    def detect_noise(self):\n        if len(self.brightpix_df)>150:\n            self.noisy.append(1)\n        else:\n            self.noisy.append(0)\n    \n\n    \n    \n    \n    def assemble(self, binary_array, thresh=20):\n        self.binary_array= binary_array\n        self.thresh= thresh\n        \n        for i in range(len(self.binary_array)):\n            self.temp = self.binary_array[i]\n            \n            self.lin_reg(self.temp)\n            self.big_and_most_gap()\n            \n            \n            \n            \n            self.gap_detector()\n            self.mean_squiggliness()\n            self.find_bright_lines()\n            self.detect_noise()\n        self.Features_DF = pd.DataFrame(np.column_stack([self.lr_rmse, self.lr_max_error, self.lr_spread, self.lr_av_slope,\n                                        self.noisy, self.mean_squiggly, self.num_bright_pix, self.pct_bright_lines, \n                                        self.num_gaps, self.biggest_gap]),\n                                       columns=['RMSE', 'Max Error', 'Spread','Slope', 'Is Noisy','Mean Squiggliness',\n                                               'Num Bright Pix', 'Pct Bright Lines','Num Gaps','Biggest Gap'])\n        self.Features_DF.fillna(0, inplace=True)\n        return self.Features_DF\n            \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:48:15.859359Z","iopub.execute_input":"2022-01-25T16:48:15.859723Z","iopub.status.idle":"2022-01-25T16:48:15.886078Z","shell.execute_reply.started":"2022-01-25T16:48:15.859687Z","shell.execute_reply":"2022-01-25T16:48:15.885414Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class EnsembleModel():\n   \n    def __init__(self, X_train , y_train , train_features, X_test, y_test, test_features, cnn_path):\n        \n        \n        self.X_Train_Features= train_features\n        self.X_Train_Data= X_train\n        self.y_train= y_train\n\n        self.X_Test_Features= test_features\n        self.X_Test_Data= X_test\n        self.y_test= y_test\n        \n        self.ytr= to_categorical([classes.index(i) for i in self.y_train])\n        \n        self.cnn_model= tf.keras.models.load_model(cnn_path)\n        \n        self.classes= ['brightpixel','narrowband', 'narrowbanddrd', 'noise', 'squarepulsednarrowband', 'squiggle', 'squigglesquarepulsednarrowband']\n    \n        \n    def cnn_only_predictions(self):\n        \n        ### NB, N, SPNB\n        \n        nb_imgs_tr= self.X_Train_Data[800:1600]\n        nb_imgs_te= self.X_Test_Data[100:200]\n        \n        n_imgs_tr= self.X_Train_Data[2400:3200]\n        n_imgs_te= self.X_Test_Data[300:400]\n        \n        spnb_imgs_tr= self.X_Train_Data[3200:4000]\n        spnb_imgs_te= self.X_Test_Data[400:500]\n        \n        \n        \n        onlycnn_X_train= np.concatenate([nb_imgs_tr,n_imgs_tr,spnb_imgs_tr])\n        onlycnn_y_train= np.concatenate([self.ytr[800:1600], self.ytr[2400:3200], self.ytr[3200:4000]])\n        \n        onlycnn_X_test= np.concatenate([nb_imgs_te, n_imgs_te,spnb_imgs_te  ])\n        self.onlycnn_y_test= np.concatenate([self.y_test[100:200], self.y_test[300:400], self.y_test[400:500] ])\n        \n        self.cnn_model.fit(onlycnn_X_train, onlycnn_y_train)\n        onlycnn_preds= self.cnn_model.predict(onlycnn_X_test)\n        \n        index_preds= np.argmax(onlycnn_preds, axis=1)\n        \n        self.pure_cnn_preds = [self.classes[i] for i in index_preds]\n        \n    \n    def combo_predictions(self):\n        \n        ### BP, NBDRD, S, SSPNB\n        \n        bp_imgs_tr= self.X_Train_Data[0:800]\n        bp_imgs_te= self.X_Test_Data[0:100]\n        \n        drd_imgs_tr= self.X_Train_Data[1600:2400]\n        drd_imgs_te= self.X_Test_Data[200:300]\n\n        s_imgs_tr= self.X_Train_Data[4000:4800]\n        s_imgs_te= self.X_Test_Data[500:600]\n        \n        sspnb_imgs_tr= self.X_Train_Data[4800:5600]\n        sspnb_imgs_te= self.X_Test_Data[600:700]\n        \n        combocnn_X_train= np.concatenate([  bp_imgs_tr,  drd_imgs_tr,   s_imgs_tr,  sspnb_imgs_tr    ])\n        combocnn_y_train= np.concatenate([ self.ytr[0:800] , self.ytr[1600:2400] ,  self.ytr[4000:4800],  self.ytr[4800:5600]   ])\n        \n        combocnn_X_test= np.concatenate([  bp_imgs_te,  drd_imgs_te ,   s_imgs_te,  sspnb_imgs_te   ])\n        self.combo_y_test= np.concatenate([    self.y_test[0:100] , self.y_test[200:300] ,  self.y_test[500:600],  self.y_test[600:700]   ])\n        \n        self.cnn_model.fit(combocnn_X_train, combocnn_y_train)\n        combocnn_train_preds= self.cnn_model.predict(combocnn_X_train)\n        combocnn_test_preds= self.cnn_model.predict(combocnn_X_test)\n        \n        index_preds= np.argmax(combocnn_test_preds, 1)\n        \n        \n        # create df \n        \n        bp_tr= self.X_Train_Features[0:800]\n        bp_te= self.X_Test_Features[0:100]\n\n        drd_tr= self.X_Train_Features[1600:2400]\n        drd_te= self.X_Test_Features[200:300]\n\n        s_tr= self.X_Train_Features[4000:4800]\n        s_te= self.X_Test_Features[500:600]\n\n        sspnb_tr= self.X_Train_Features[4800:5600]\n        sspnb_te= self.X_Test_Features[600:700]\n        \n        combo_train_feats= pd.concat([bp_tr ,drd_tr, s_tr,  sspnb_tr  ], axis=0)\n        combo_train_feats.reset_index(drop=True, inplace=True)\n        combo_train_feats.drop(columns='Is Noisy', inplace=True)\n        \n        combo_test_feats= pd.concat([bp_te ,drd_te, s_te,  sspnb_te  ], axis=0)\n        combo_test_feats.reset_index(drop=True, inplace=True)\n        combo_test_feats.drop(columns='Is Noisy', inplace=True)\n        \n        \n        combo_y_train= np.concatenate([   self.y_train[0:800], self.y_train[1600:2400],  self.y_train[4000:4800],  self.y_train[4800:5600]     ])\n        \n        \n        combo_probs_train= pd.DataFrame(combocnn_train_preds)\n        combo_probs_train= combo_probs_train.rename(columns={0:'BP Prob', 1:'NB Prob', 2:'NBDRD Prob', 3:'N Prob',4:'SPNB Prob',5:'S Prob',6:'SSPNB Prob'})\n        \n        combo_probs_test= pd.DataFrame(combocnn_test_preds)\n        combo_probs_test= combo_probs_test.rename(columns={0:'BP Prob', 1:'NB Prob', 2:'NBDRD Prob', 3:'N Prob',4:'SPNB Prob',5:'S Prob',6:'SSPNB Prob'})\n        \n        self.combo_X_train= pd.concat([combo_train_feats, combo_probs_train ], axis=1)\n        combo_X_test= pd.concat([combo_test_feats,  combo_probs_test], axis=1)\n        \n        rf= RandomForestClassifier(criterion='entropy', max_depth=11, max_features=5, n_estimators=100)\n        rf.fit(self.combo_X_train, combo_y_train)\n        self.combo_preds= rf.predict(combo_X_test)\n        self.ens_feature_importances_ = rf.feature_importances_\n        \n        \n    def build_ensemble(self):\n        self.cnn_only_predictions()\n        self.combo_predictions()\n        \n        self.final_preds= np.concatenate([self.pure_cnn_preds, self.combo_preds])\n        self.y_actual= np.concatenate([self.onlycnn_y_test, self.combo_y_test])\n        self.accuracy= accuracy_score(self.y_actual,  self.final_preds )\n\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:43:21.196640Z","iopub.execute_input":"2022-01-25T17:43:21.196966Z","iopub.status.idle":"2022-01-25T17:43:21.250614Z","shell.execute_reply.started":"2022-01-25T17:43:21.196931Z","shell.execute_reply":"2022-01-25T17:43:21.249872Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train= ImageData(train_path)\nX_tr, y_tr= train.split_and_resize()\nX_tr_bin= train.create_binary_image()\n\nclasses= train.classes","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:48:15.910837Z","iopub.execute_input":"2022-01-25T16:48:15.911361Z","iopub.status.idle":"2022-01-25T16:49:50.401920Z","shell.execute_reply.started":"2022-01-25T16:48:15.911316Z","shell.execute_reply":"2022-01-25T16:49:50.401157Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# valid= ImageData(valid_path)\n# X_val, y_val= valid.split_and_resize()\n# X_val_bin= valid.create_binary_image()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:49:50.404113Z","iopub.execute_input":"2022-01-25T16:49:50.404379Z","iopub.status.idle":"2022-01-25T16:49:50.408717Z","shell.execute_reply.started":"2022-01-25T16:49:50.404344Z","shell.execute_reply":"2022-01-25T16:49:50.408062Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"test= ImageData(test_path)\nX_te, y_te= test.split_and_resize()\nX_te_bin= test.create_binary_image()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:49:50.409731Z","iopub.execute_input":"2022-01-25T16:49:50.410370Z","iopub.status.idle":"2022-01-25T16:50:03.029504Z","shell.execute_reply.started":"2022-01-25T16:49:50.410334Z","shell.execute_reply":"2022-01-25T16:50:03.028738Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"fe_train= FeatureEngineering()\nTRAIN_DF= fe_train.assemble(X_tr_bin, thresh=10)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T16:50:03.030621Z","iopub.execute_input":"2022-01-25T16:50:03.030876Z","iopub.status.idle":"2022-01-25T17:01:54.628369Z","shell.execute_reply.started":"2022-01-25T16:50:03.030843Z","shell.execute_reply":"2022-01-25T17:01:54.627636Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# fe_valid = FeatureEngineering()\n# VAL_DF= fe_valid.assemble(X_val_bin, thresh=10)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T03:22:58.667345Z","iopub.execute_input":"2022-01-25T03:22:58.667589Z","iopub.status.idle":"2022-01-25T03:22:58.672465Z","shell.execute_reply.started":"2022-01-25T03:22:58.667555Z","shell.execute_reply":"2022-01-25T03:22:58.670785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fe_test= FeatureEngineering()\nTEST_DF= fe_test.assemble(X_te_bin, thresh=10)","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:01:54.629636Z","iopub.execute_input":"2022-01-25T17:01:54.629883Z","iopub.status.idle":"2022-01-25T17:03:25.145722Z","shell.execute_reply.started":"2022-01-25T17:01:54.629851Z","shell.execute_reply":"2022-01-25T17:03:25.144947Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"del X_tr_bin\ndel X_te_bin\ndel train\ndel test\ndel FeatureEngineering\ndel fe_train\ndel fe_test\n","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:03:25.146993Z","iopub.execute_input":"2022-01-25T17:03:25.147251Z","iopub.status.idle":"2022-01-25T17:03:25.230436Z","shell.execute_reply.started":"2022-01-25T17:03:25.147218Z","shell.execute_reply":"2022-01-25T17:03:25.229753Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:03:25.231582Z","iopub.execute_input":"2022-01-25T17:03:25.231956Z","iopub.status.idle":"2022-01-25T17:03:25.391628Z","shell.execute_reply.started":"2022-01-25T17:03:25.231921Z","shell.execute_reply":"2022-01-25T17:03:25.390949Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"cnn_path= '../input/88-model/VGG16_model88acc.h5'\ne= EnsembleModel(X_tr, y_tr, TRAIN_DF, X_te, y_te, TEST_DF, cnn_path)\ne.build_ensemble()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:43:45.048776Z","iopub.execute_input":"2022-01-25T17:43:45.049594Z","iopub.status.idle":"2022-01-25T17:44:00.498552Z","shell.execute_reply.started":"2022-01-25T17:43:45.049546Z","shell.execute_reply":"2022-01-25T17:44:00.497799Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"e.accuracy","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:44:00.500185Z","iopub.execute_input":"2022-01-25T17:44:00.500448Z","iopub.status.idle":"2022-01-25T17:44:00.506996Z","shell.execute_reply.started":"2022-01-25T17:44:00.500411Z","shell.execute_reply":"2022-01-25T17:44:00.506284Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"e.ens_feature_importances_","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:44:00.508176Z","iopub.execute_input":"2022-01-25T17:44:00.508592Z","iopub.status.idle":"2022-01-25T17:44:00.517600Z","shell.execute_reply.started":"2022-01-25T17:44:00.508555Z","shell.execute_reply":"2022-01-25T17:44:00.516753Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nsns.set_style('darkgrid')\nsorted_idx= e.ens_feature_importances_.argsort()[:]\nplt.barh(e.combo_X_train.columns[sorted_idx], e.ens_feature_importances_[sorted_idx])\nplt.xlabel('Feature Importance')\nplt.ylabel(\"Image Type\")\nplt.title(\"Random Forest Feature Importances\")\nplt.show","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:44:10.359860Z","iopub.execute_input":"2022-01-25T17:44:10.360589Z","iopub.status.idle":"2022-01-25T17:44:10.740972Z","shell.execute_reply.started":"2022-01-25T17:44:10.360546Z","shell.execute_reply":"2022-01-25T17:44:10.740262Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"classes_abv= ['BP','NB','NBDRD','N','SPNB','S','SSPNB']","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:44:37.139824Z","iopub.execute_input":"2022-01-25T17:44:37.140081Z","iopub.status.idle":"2022-01-25T17:44:37.143977Z","shell.execute_reply.started":"2022-01-25T17:44:37.140052Z","shell.execute_reply":"2022-01-25T17:44:37.143174Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\ncm= confusion_matrix(e.y_actual, e.final_preds)\ncm_df= pd.DataFrame(cm, columns=list(classes), index= list(classes))\ncm_df\nax = sns.heatmap(cm, annot=True, cmap='Purples')\n\nax.set_title('Ensemble Model Confusion Matrix')\nax.set_xlabel('Predicted Image Type')\nax.set_ylabel('Actual Image Type')\nax.xaxis.set_ticklabels(list(classes_abv), rotation= 270)\nax.yaxis.set_ticklabels(list(classes_abv), rotation= 360)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:44:37.808255Z","iopub.execute_input":"2022-01-25T17:44:37.809144Z","iopub.status.idle":"2022-01-25T17:44:38.258848Z","shell.execute_reply.started":"2022-01-25T17:44:37.809089Z","shell.execute_reply":"2022-01-25T17:44:38.258122Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"cls_report= classification_report(e.y_actual, e.final_preds, output_dict= True)\ncls_report= pd.DataFrame(cls_report).T\ncls_report","metadata":{"execution":{"iopub.status.busy":"2022-01-25T17:44:52.345279Z","iopub.execute_input":"2022-01-25T17:44:52.345782Z","iopub.status.idle":"2022-01-25T17:44:52.376109Z","shell.execute_reply.started":"2022-01-25T17:44:52.345743Z","shell.execute_reply":"2022-01-25T17:44:52.375299Z"},"trusted":true},"execution_count":32,"outputs":[]}]}